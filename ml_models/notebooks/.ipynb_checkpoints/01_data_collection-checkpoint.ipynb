{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Data Collection and Initial Exploration\n",
    "\n",
    "This notebook covers:\n",
    "1. Loading downloaded Kaggle datasets\n",
    "2. Creating custom ingredient toxicity database\n",
    "3. Initial data exploration\n",
    "4. Data quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set up paths\n",
    "DATA_RAW = Path('../data/raw')\n",
    "DATA_PROCESSED = Path('../data/processed')\n",
    "DATA_PROCESSED.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"üìÅ Raw data directory: {DATA_RAW}\")\n",
    "print(f\"üìÅ Processed data directory: {DATA_PROCESSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files we have downloaded\n",
    "print(\"üìã Files in raw data directory:\")\n",
    "for file in DATA_RAW.glob('*'):\n",
    "    if file.is_file():\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  üìÑ {file.name} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom ingredient toxicity database\n",
    "import sys\n",
    "sys.path.append('../src/data')\n",
    "\n",
    "from create_ingredient_db import create_ingredient_toxicity_db\n",
    "\n",
    "# Create the database\n",
    "ingredient_db = create_ingredient_toxicity_db()\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüîç First 10 ingredients:\")\n",
    "ingredient_db.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kaggle datasets (if available)\n",
    "datasets = {}\n",
    "\n",
    "# Try to load common food dataset files\n",
    "possible_files = [\n",
    "    'nutrition.csv',\n",
    "    'food_nutrition.csv', \n",
    "    'recipes.csv',\n",
    "    'food_data.csv',\n",
    "    'ingredients.csv'\n",
    "]\n",
    "\n",
    "for filename in possible_files:\n",
    "    filepath = DATA_RAW / filename\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            datasets[filename] = df\n",
    "            print(f\"‚úÖ Loaded {filename}: {df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {filename} not found\")\n",
    "\n",
    "print(f\"\\nüìä Total datasets loaded: {len(datasets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore our custom ingredient database\n",
    "print(\"üìä Ingredient Database Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"Total ingredients: {len(ingredient_db)}\")\n",
    "print(f\"Average toxicity score: {ingredient_db['toxicity_score'].mean():.1f}\")\n",
    "print(f\"Median toxicity score: {ingredient_db['toxicity_score'].median():.1f}\")\n",
    "\n",
    "print(\"\\nüìà Risk Level Distribution:\")\n",
    "print(ingredient_db['risk_level'].value_counts())\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Category Distribution:\")\n",
    "print(ingredient_db['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Toxicity score distribution\n",
    "axes[0,0].hist(ingredient_db['toxicity_score'], bins=20, alpha=0.7, color='red', edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Toxicity Scores')\n",
    "axes[0,0].set_xlabel('Toxicity Score (0-100)')\n",
    "axes[0,0].set_ylabel('Number of Ingredients')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Risk level pie chart\n",
    "risk_counts = ingredient_db['risk_level'].value_counts()\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "axes[0,1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "axes[0,1].set_title('Risk Level Distribution')\n",
    "\n",
    "# 3. Category distribution\n",
    "category_counts = ingredient_db['category'].value_counts()\n",
    "axes[1,0].bar(range(len(category_counts)), category_counts.values)\n",
    "axes[1,0].set_title('Ingredient Categories')\n",
    "axes[1,0].set_xlabel('Category')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_xticks(range(len(category_counts)))\n",
    "axes[1,0].set_xticklabels(category_counts.index, rotation=45, ha='right')\n",
    "\n",
    "# 4. Toxicity by category boxplot\n",
    "ingredient_db.boxplot(column='toxicity_score', by='risk_level', ax=axes[1,1])\n",
    "axes[1,1].set_title('Toxicity Score by Risk Level')\n",
    "axes[1,1].set_xlabel('Risk Level')\n",
    "axes[1,1].set_ylabel('Toxicity Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/week2_data_exploration.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualizations saved to reports/figures/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "print(\"üîç Data Quality Assessment\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(ingredient_db.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = ingredient_db.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicates}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(ingredient_db.dtypes)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics for toxicity_score:\")\n",
    "print(ingredient_db['toxicity_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "print(\"üíæ Saving processed data...\")\n",
    "\n",
    "# Save ingredient database\n",
    "ingredient_db.to_csv(DATA_PROCESSED / 'ingredient_toxicity_db.csv', index=False)\n",
    "print(f\"‚úÖ Saved ingredient database: {len(ingredient_db)} rows\")\n",
    "\n",
    "# Save any loaded Kaggle datasets to processed folder\n",
    "for name, df in datasets.items():\n",
    "    processed_name = f\"processed_{name}\"\n",
    "    df.to_csv(DATA_PROCESSED / processed_name, index=False)\n",
    "    print(f\"‚úÖ Saved {processed_name}: {df.shape}\")\n",
    "\n",
    "print(\"\\nüéâ Week 2 Data Collection Complete!\")\n",
    "print(\"\\nüìã Next Steps (Week 3):\")\n",
    "print(\"  1. Exploratory Data Analysis (EDA)\")\n",
    "print(\"  2. Data preprocessing\")\n",
    "print(\"  3. Feature engineering\")\n",
    "print(\"  4. Data splitting for ML\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}