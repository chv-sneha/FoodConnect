{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook covers:\n",
    "1. Statistical analysis of datasets\n",
    "2. Data visualization and patterns\n",
    "3. Correlation analysis\n",
    "4. Feature distribution analysis\n",
    "5. Data quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set up paths\n",
    "DATA_RAW = Path('../data/raw')\n",
    "DATA_PROCESSED = Path('../data/processed')\n",
    "REPORTS = Path('../reports/figures')\n",
    "REPORTS.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Libraries imported and paths set up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all available datasets\n",
    "print(\"üìä Loading datasets...\")\n",
    "\n",
    "# Load ingredient toxicity database\n",
    "ingredient_db = pd.read_csv(DATA_PROCESSED / 'ingredient_toxicity_db.csv')\n",
    "print(f\"‚úÖ Ingredient DB: {ingredient_db.shape}\")\n",
    "\n",
    "# Load Kaggle food datasets\n",
    "try:\n",
    "    food_df = pd.read_csv(DATA_RAW / 'food.csv')\n",
    "    print(f\"‚úÖ Food dataset: {food_df.shape}\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Food.csv not found\")\n",
    "    food_df = None\n",
    "\n",
    "try:\n",
    "    food1_df = pd.read_csv(DATA_RAW / 'food1.csv')\n",
    "    print(f\"‚úÖ Food1 dataset: {food1_df.shape}\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Food1.csv not found\")\n",
    "    food1_df = None\n",
    "\n",
    "print(\"\\nüìã Available datasets for analysis:\")\n",
    "print(f\"  - Ingredient Toxicity DB: {len(ingredient_db)} ingredients\")\n",
    "if food_df is not None:\n",
    "    print(f\"  - Food Dataset: {len(food_df)} records\")\n",
    "if food1_df is not None:\n",
    "    print(f\"  - Food1 Dataset: {len(food1_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of ingredient database\n",
    "print(\"üîç INGREDIENT DATABASE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic info\n",
    "print(\"\\nüìä Basic Information:\")\n",
    "print(f\"Shape: {ingredient_db.shape}\")\n",
    "print(f\"Columns: {list(ingredient_db.columns)}\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\nüè∑Ô∏è Data Types:\")\n",
    "print(ingredient_db.dtypes)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\n‚ùì Missing Values:\")\n",
    "missing = ingredient_db.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìà Summary Statistics:\")\n",
    "ingredient_db.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical analysis\n",
    "print(\"üè∑Ô∏è CATEGORICAL ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "categorical_cols = ['category', 'health_impact', 'risk_level', 'allergen_risk']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in ingredient_db.columns:\n",
    "        print(f\"\\nüìä {col.upper()} Distribution:\")\n",
    "        counts = ingredient_db[col].value_counts()\n",
    "        percentages = ingredient_db[col].value_counts(normalize=True) * 100\n",
    "        \n",
    "        for category, count in counts.items():\n",
    "            pct = percentages[category]\n",
    "            print(f\"  {category}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "print(\"üìä Creating visualizations...\")\n",
    "\n",
    "# Set up the figure with subplots\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Toxicity Score Distribution\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.hist(ingredient_db['toxicity_score'], bins=15, alpha=0.7, color='red', edgecolor='black')\n",
    "plt.title('Toxicity Score Distribution', fontweight='bold')\n",
    "plt.xlabel('Toxicity Score (0-100)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Risk Level Pie Chart\n",
    "plt.subplot(3, 3, 2)\n",
    "risk_counts = ingredient_db['risk_level'].value_counts()\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "plt.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', \n",
    "        colors=colors[:len(risk_counts)], startangle=90)\n",
    "plt.title('Risk Level Distribution', fontweight='bold')\n",
    "\n",
    "# 3. Category Bar Chart\n",
    "plt.subplot(3, 3, 3)\n",
    "category_counts = ingredient_db['category'].value_counts()\n",
    "bars = plt.bar(range(len(category_counts)), category_counts.values, \n",
    "               color=sns.color_palette(\"husl\", len(category_counts)))\n",
    "plt.title('Ingredient Categories', fontweight='bold')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(len(category_counts)), category_counts.index, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Toxicity by Category Box Plot\n",
    "plt.subplot(3, 3, 4)\n",
    "sns.boxplot(data=ingredient_db, x='risk_level', y='toxicity_score', \n",
    "            order=['Safe', 'Low Risk', 'Medium Risk', 'High Risk'])\n",
    "plt.title('Toxicity Score by Risk Level', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 5. Health Impact Distribution\n",
    "plt.subplot(3, 3, 5)\n",
    "health_counts = ingredient_db['health_impact'].value_counts()\n",
    "plt.bar(health_counts.index, health_counts.values, \n",
    "        color=['green', 'lightgreen', 'yellow', 'orange', 'red'][:len(health_counts)])\n",
    "plt.title('Health Impact Distribution', fontweight='bold')\n",
    "plt.xlabel('Health Impact')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Allergen Risk Analysis\n",
    "plt.subplot(3, 3, 6)\n",
    "allergen_counts = ingredient_db['allergen_risk'].value_counts()\n",
    "plt.pie(allergen_counts.values, labels=allergen_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Allergen Risk Distribution', fontweight='bold')\n",
    "\n",
    "# 7. Toxicity Score vs Category Scatter\n",
    "plt.subplot(3, 3, 7)\n",
    "categories = ingredient_db['category'].unique()\n",
    "for i, cat in enumerate(categories):\n",
    "    cat_data = ingredient_db[ingredient_db['category'] == cat]\n",
    "    plt.scatter([i] * len(cat_data), cat_data['toxicity_score'], \n",
    "               alpha=0.6, s=50, label=cat)\n",
    "plt.title('Toxicity Scores by Category', fontweight='bold')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Toxicity Score')\n",
    "plt.xticks(range(len(categories)), categories, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Binary Classification Distribution\n",
    "plt.subplot(3, 3, 8)\n",
    "toxic_counts = ingredient_db['is_toxic'].value_counts()\n",
    "labels = ['Non-Toxic (‚â§50)', 'Toxic (>50)']\n",
    "plt.bar(labels, toxic_counts.values, color=['green', 'red'], alpha=0.7)\n",
    "plt.title('Binary Toxicity Classification', fontweight='bold')\n",
    "plt.ylabel('Count')\n",
    "for i, v in enumerate(toxic_counts.values):\n",
    "    plt.text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 9. Top 10 Most Toxic Ingredients\n",
    "plt.subplot(3, 3, 9)\n",
    "top_toxic = ingredient_db.nlargest(10, 'toxicity_score')\n",
    "plt.barh(range(len(top_toxic)), top_toxic['toxicity_score'], color='red', alpha=0.7)\n",
    "plt.title('Top 10 Most Toxic Ingredients', fontweight='bold')\n",
    "plt.xlabel('Toxicity Score')\n",
    "plt.yticks(range(len(top_toxic)), top_toxic['ingredient_name'])\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS / 'week3_comprehensive_eda.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Comprehensive EDA visualizations created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"üîó CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Select numeric columns for correlation\n",
    "numeric_cols = ingredient_db.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Numeric columns: {list(numeric_cols)}\")\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = ingredient_db[numeric_cols].corr()\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "                square=True, fmt='.3f', cbar_kws={'shrink': 0.8})\n",
    "    plt.title('Correlation Matrix - Ingredient Database', fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS / 'correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Correlation Matrix:\")\n",
    "    print(corr_matrix)\nelse:\n",
    "    print(\"‚ö†Ô∏è Not enough numeric columns for correlation analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze food datasets if available\n",
    "if food_df is not None:\n",
    "    print(\"üçé FOOD DATASET ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nüìä Food Dataset Shape: {food_df.shape}\")\n",
    "    print(f\"Columns: {list(food_df.columns)}\")\n",
    "    \n",
    "    # First few rows\n",
    "    print(\"\\nüîç First 5 rows:\")\n",
    "    display(food_df.head())\n",
    "    \n",
    "    # Data types and missing values\n",
    "    print(\"\\nüè∑Ô∏è Data Info:\")\n",
    "    print(food_df.info())\n",
    "    \n",
    "    # Missing values analysis\n",
    "    missing_food = food_df.isnull().sum()\n",
    "    if missing_food.sum() > 0:\n",
    "        print(\"\\n‚ùì Missing Values:\")\n",
    "        missing_pct = (missing_food / len(food_df)) * 100\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Missing Count': missing_food[missing_food > 0],\n",
    "            'Missing %': missing_pct[missing_food > 0]\n",
    "        })\n",
    "        print(missing_df)\n",
    "    \n",
    "    # Numeric columns analysis\n",
    "    numeric_food_cols = food_df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_food_cols) > 0:\n",
    "        print(f\"\\nüìà Numeric columns: {list(numeric_food_cols)}\")\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        display(food_df[numeric_food_cols].describe())\nelse:\n",
    "    print(\"‚ö†Ô∏è Food dataset not available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical insights and patterns\n",
    "print(\"üìà STATISTICAL INSIGHTS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Toxicity statistics by category\n",
    "print(\"\\nüè∑Ô∏è Toxicity Statistics by Category:\")\n",
    "category_stats = ingredient_db.groupby('category')['toxicity_score'].agg([\n",
    "    'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "]).round(2)\n",
    "category_stats = category_stats.sort_values('mean', ascending=False)\n",
    "print(category_stats)\n",
    "\n",
    "# Risk level statistics\n",
    "print(\"\\n‚ö†Ô∏è Risk Level Statistics:\")\n",
    "risk_stats = ingredient_db.groupby('risk_level')['toxicity_score'].agg([\n",
    "    'count', 'mean', 'min', 'max'\n",
    "]).round(2)\n",
    "print(risk_stats)\n",
    "\n",
    "# Most and least toxic ingredients\n",
    "print(\"\\nüî¥ TOP 5 MOST TOXIC INGREDIENTS:\")\n",
    "most_toxic = ingredient_db.nlargest(5, 'toxicity_score')[['ingredient_name', 'toxicity_score', 'category', 'health_impact']]\n",
    "for idx, row in most_toxic.iterrows():\n",
    "    print(f\"  {row['ingredient_name']}: {row['toxicity_score']} ({row['category']}, {row['health_impact']})\")\n",
    "\n",
    "print(\"\\nüü¢ TOP 5 SAFEST INGREDIENTS:\")\n",
    "safest = ingredient_db.nsmallest(5, 'toxicity_score')[['ingredient_name', 'toxicity_score', 'category', 'health_impact']]\n",
    "for idx, row in safest.iterrows():\n",
    "    print(f\"  {row['ingredient_name']}: {row['toxicity_score']} ({row['category']}, {row['health_impact']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "print(\"‚úÖ DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = ingredient_db.duplicated().sum()\n",
    "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")\n",
    "\n",
    "# Check for outliers in toxicity scores\n",
    "Q1 = ingredient_db['toxicity_score'].quantile(0.25)\n",
    "Q3 = ingredient_db['toxicity_score'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = ingredient_db[\n",
    "    (ingredient_db['toxicity_score'] < lower_bound) | \n",
    "    (ingredient_db['toxicity_score'] > upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä Outliers in toxicity scores: {len(outliers)}\")\n",
    "if len(outliers) > 0:\n",
    "    print(\"Outlier ingredients:\")\n",
    "    for idx, row in outliers.iterrows():\n",
    "        print(f\"  {row['ingredient_name']}: {row['toxicity_score']}\")\n",
    "\n",
    "# Data completeness\n",
    "completeness = (1 - ingredient_db.isnull().sum() / len(ingredient_db)) * 100\n",
    "print(f\"\\nüìã Data Completeness:\")\n",
    "for col, pct in completeness.items():\n",
    "    print(f\"  {col}: {pct:.1f}%\")\n",
    "\n",
    "# Overall data quality score\n",
    "avg_completeness = completeness.mean()\n",
    "quality_score = avg_completeness * (1 - duplicates/len(ingredient_db))\n",
    "print(f\"\\nüéØ Overall Data Quality Score: {quality_score:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate EDA summary report\n",
    "print(\"üìã EDA SUMMARY REPORT\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "summary_report = {\n",
    "    'Dataset Info': {\n",
    "        'Total Ingredients': len(ingredient_db),\n",
    "        'Features': len(ingredient_db.columns),\n",
    "        'Numeric Features': len(ingredient_db.select_dtypes(include=[np.number]).columns),\n",
    "        'Categorical Features': len(ingredient_db.select_dtypes(include=['object']).columns)\n",
    "    },\n",
    "    'Toxicity Analysis': {\n",
    "        'Mean Toxicity Score': ingredient_db['toxicity_score'].mean(),\n",
    "        'Median Toxicity Score': ingredient_db['toxicity_score'].median(),\n",
    "        'Std Deviation': ingredient_db['toxicity_score'].std(),\n",
    "        'High Risk Ingredients': len(ingredient_db[ingredient_db['risk_level'] == 'High Risk']),\n",
    "        'Safe Ingredients': len(ingredient_db[ingredient_db['risk_level'] == 'Safe'])\n",
    "    },\n",
    "    'Data Quality': {\n",
    "        'Missing Values': ingredient_db.isnull().sum().sum(),\n",
    "        'Duplicate Rows': duplicates,\n",
    "        'Outliers': len(outliers),\n",
    "        'Quality Score': f\"{quality_score:.1f}%\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for section, metrics in summary_report.items():\n",
    "    print(f\"\\nüìä {section}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {metric}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Save summary to file\n",
    "import json\n",
    "with open(REPORTS.parent / 'eda_summary_report.json', 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\nüíæ EDA summary report saved to reports/eda_summary_report.json\")\n",
    "print(\"\\nüéâ Week 3 EDA Analysis Complete!\")\n",
    "print(\"\\nüìã Next Steps (Week 4):\")\n",
    "print(\"  1. Data preprocessing and cleaning\")\n",
    "print(\"  2. Feature engineering\")\n",
    "print(\"  3. Data splitting for ML\")\n",
    "print(\"  4. Model development preparation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}